{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4a8517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d36b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Selenium webdriver\n",
    "driver = webdriver.Chrome()\n",
    "url = 'https://finance.yahoo.com/quote/TATAPOWER.NS/history?period1=820454400&period2=1682899200&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true'\n",
    "driver.get(url)\n",
    "# Wait for the page to load\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afe9094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll to the bottom of the page to load more data\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac14713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep scrolling until the desired number of rows is reached\n",
    "while len(driver.find_elements('xpath', '//table/tbody/tr')) < 100:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d01cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the page source after scrolling\n",
    "page_source = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68227a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the Selenium webdriver\n",
    "driver.quit()\n",
    "driver = webdriver.Chrome(executable_path=chromedriver_path, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ef6307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BeautifulSoup object with the page source\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9962ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the table containing the historical data\n",
    "table = soup.find('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f99f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store the data\n",
    "dates = []\n",
    "open_prices = []\n",
    "high_prices = []\n",
    "low_prices = []\n",
    "close_prices = []\n",
    "adj_close_prices = []\n",
    "volumes = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from each row of the table\n",
    "for row in table.tbody.find_all('tr'):\n",
    "    cols = row.find_all('td')\n",
    "    if len(cols) == 7:\n",
    "        date = cols[0].text\n",
    "        open_price = float(cols[1].text.replace(',', ''))\n",
    "        high_price = float(cols[2].text.replace(',', ''))\n",
    "        low_price = float(cols[3].text.replace(',', ''))\n",
    "        close_price = float(cols[4].text.replace(',', ''))\n",
    "        adj_close_price = float(cols[5].text.replace(',', ''))\n",
    "        volume = int(cols[6].text.replace(',', ''))\n",
    "        \n",
    "        dates.append(date)\n",
    "        open_prices.append(open_price)\n",
    "        high_prices.append(high_price)\n",
    "        low_prices.append(low_price)\n",
    "        close_prices.append(close_price)\n",
    "        adj_close_prices.append(adj_close_price)\n",
    "        volumes.append(volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a76b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the collected data\n",
    "data = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Open': open_prices,\n",
    "    'High': high_prices,\n",
    "    'Low': low_prices,\n",
    "    'Close': close_prices,\n",
    "    'Adj Close': adj_close_prices,\n",
    "    'Volume': volumes\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10ac221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path for the CSV file\n",
    "csv_file_path = 'stock_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1f2721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the CSV file exists and delete it if it does\n",
    "if os.path.exists(csv_file_path):\n",
    "    os.remove(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c25823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data as a CSV file\n",
    "data.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891692aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data saved as CSV:\", csv_file_path)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3d5a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea2f347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39339328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70125e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62248a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Set up the Selenium webdriver\n",
    "driver = webdriver.Chrome()\n",
    "url = 'https://finance.yahoo.com/quote/TATAPOWER.NS/history?period1=820454400&period2=1682899200&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true'\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Scroll to the bottom of the page to load more data\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Keep scrolling until the desired number of rows is reached\n",
    "while len(driver.find_elements('xpath', '//table/tbody/tr')) < 100:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "# Get the page source after scrolling\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Close the Selenium webdriver\n",
    "driver.quit()\n",
    "\n",
    "# Create a BeautifulSoup object with the page source\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Find the table containing the historical data\n",
    "table = soup.find('table')\n",
    "\n",
    "# Create empty lists to store the data\n",
    "dates = []\n",
    "open_prices = []\n",
    "high_prices = []\n",
    "low_prices = []\n",
    "close_prices = []\n",
    "adj_close_prices = []\n",
    "volumes = []\n",
    "\n",
    "# Extract data from each row of the table\n",
    "for row in table.tbody.find_all('tr'):\n",
    "    cols = row.find_all('td')\n",
    "    if len(cols) == 7:\n",
    "        date = cols[0].text\n",
    "        open_price = float(cols[1].text.replace(',', ''))\n",
    "        high_price = float(cols[2].text.replace(',', ''))\n",
    "        low_price = float(cols[3].text.replace(',', ''))\n",
    "        close_price = float(cols[4].text.replace(',', ''))\n",
    "        adj_close_price = float(cols[5].text.replace(',', ''))\n",
    "        volume = int(cols[6].text.replace(',', ''))\n",
    "        \n",
    "        dates.append(date)\n",
    "        open_prices.append(open_price)\n",
    "        high_prices.append(high_price)\n",
    "        low_prices.append(low_price)\n",
    "        close_prices.append(close_price)\n",
    "        adj_close_prices.append(adj_close_price)\n",
    "        volumes.append(volume)\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "data = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Open': open_prices,\n",
    "    'High': high_prices,\n",
    "    'Low': low_prices,\n",
    "    'Close': close_prices,\n",
    "    'Adj Close': adj_close_prices,\n",
    "    'Volume': volumes\n",
    "})\n",
    "\n",
    "# Define the file path for the CSV file\n",
    "csv_file_path = 'stock_data.csv'\n",
    "\n",
    "# Check if the CSV file exists and delete it if it does\n",
    "if os.path.exists(csv_file_path):\n",
    "    os.remove(csv_file_path)\n",
    "\n",
    "# Save the data as a CSV file\n",
    "data.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(\"Data saved as CSV:\", csv_file_path)\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52801670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "\n",
    "# Set up Chrome driver\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "chrome_driver_path = \"path_to_chromedriver\"  # Set the path to your chromedriver executable\n",
    "service = Service(chrome_driver_path)\n",
    "\n",
    "# Set up data directory and file path\n",
    "data_dir = \"data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "file_path = os.path.join(data_dir, \"stock_data.csv\")\n",
    "\n",
    "# Launch Chrome driver\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Define the URL of the website to scrape\n",
    "url = \"https://finance.yahoo.com/quote/TATAPOWER.NS/history?period1=820454400&period2=1682899200&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true\"\n",
    "\n",
    "# Open the website\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Scroll to the bottom of the page to load more data\n",
    "html = driver.find_element(By.TAG_NAME, 'html')\n",
    "html.send_keys(Keys.END)\n",
    "time.sleep(3)\n",
    "\n",
    "# Keep scrolling until the desired number of rows is reached\n",
    "while len(driver.find_elements(By.XPATH, '//table/tbody/tr')) < 1000:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "# Get the table data\n",
    "table = driver.find_element(By.XPATH, '//table')\n",
    "rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "# Extract the data from the table\n",
    "data = []\n",
    "for row in rows:\n",
    "    cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "    if cells:\n",
    "        row_data = [cell.text for cell in cells]\n",
    "        data.append(row_data)\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(data, columns=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"])\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n",
    "\n",
    "# Perform AI and DL tasks on the collected data (e.g., stock price prediction)\n",
    "# ... Your AI and DL code goes here ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c8f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5796a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bdeb08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48d0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e2b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148c4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee054aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99684db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3890d0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2446e030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d3c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c8095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc54476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62096381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8895df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd34c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57851e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2804c70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca2651f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e68710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffda968d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4383611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc02dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "\n",
    "# Set up Chrome driver\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "chrome_driver_path = \"path_to_chromedriver\"  # Set the path to your chromedriver executable\n",
    "service = Service(chrome_driver_path)\n",
    "\n",
    "# Set up data directory and file path\n",
    "data_dir = \"data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "file_path = os.path.join(data_dir, \"stock_data.csv\")\n",
    "\n",
    "# Launch Chrome driver\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Define the URL of the website to scrape\n",
    "url = \"https://finance.yahoo.com/quote/TATAPOWER.NS/history?period1=820454400&period2=1682899200&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true\"\n",
    "\n",
    "# Open the website\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Scroll to the bottom of the page to load more data\n",
    "html = driver.find_element(By.TAG_NAME, 'html')\n",
    "html.send_keys(Keys.END)\n",
    "time.sleep(3)\n",
    "\n",
    "# Keep scrolling until the desired number of rows is reached\n",
    "while len(driver.find_elements(By.XPATH, '//table/tbody/tr')) < 1000:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "# Get the table data\n",
    "table = driver.find_element(By.XPATH, '//table')\n",
    "rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "# Extract the data from the table\n",
    "data = []\n",
    "for row in rows:\n",
    "    cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "    if cells:\n",
    "        row_data = [cell.text for cell in cells]\n",
    "        data.append(row_data)\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(data, columns=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"])\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n",
    "\n",
    "# Perform AI and DL tasks on the collected data (e.g., stock price prediction)\n",
    "# ... Your AI and DL code goes here ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70cadd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
